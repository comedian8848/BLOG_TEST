{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{286:function(s,t){s.exports=\"data:image/png;base64,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\"},287:function(s,t,a){s.exports=a.p+\"assets/img/Figure_14.741e372c.png\"},288:function(s,t,a){s.exports=a.p+\"assets/img/Figure_15.ef8bf326.png\"},359:function(s,t,a){\"use strict\";a.r(t);var n=a(13),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":s.$parent.slotKey}},[t(\"blockquote\",[t(\"p\",[s._v(\"Scikit-learn（以前称为scikits.learn，也称为sklearn）是针对Python 编程语言的免费软件机器学习库。它具有各种分类，回归和聚类算法，包括支持向量机，随机森林，梯度提升，k均值和DBSCAN\")])]),s._v(\" \"),t(\"h2\",{attrs:{id:\"train-test\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#train-test\"}},[s._v(\"#\")]),s._v(\" Train & Test\")]),s._v(\" \"),t(\"h3\",{attrs:{id:\"load-digits\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#load-digits\"}},[s._v(\"#\")]),s._v(\" \"),t(\"code\",[s._v(\"load_digits\")])]),s._v(\" \"),t(\"p\",[t(\"code\",[s._v(\"scikit-learn\")]),s._v(\"中自带了很多的数据集在\"),t(\"code\",[s._v(\"sklearn.datasets\")]),s._v(\"模块中，\"),t(\"code\",[s._v(\"load_digits\")]),s._v(\"是其中一个用于识别手写数字的数据集\")]),s._v(\" \"),t(\"p\",[s._v(\"导入\"),t(\"code\",[s._v(\"load_digits\")]),s._v(\"并展示其数据集和结果\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_digits\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 关于手写数字识别的数据集\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# X的每行是64个图像像素的强度\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# y是每个图片识别出来的数字0-9\")]),s._v(\"\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_digits\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"X:\\\\n\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"y:\\\\n\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 绘制一下图片，灰度图\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"imshow\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"reshape\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"8\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"8\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cmap\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'gray'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"axis\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'off'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 关闭坐标轴\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"\\\\nthe digit in the image is: \"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(286)}}),s._v(\" \"),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"the digit \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"in\")]),s._v(\" the image is:  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"p\",[s._v(\"通过\"),t(\"code\",[s._v(\"train_test_split\")]),s._v(\"将数据集分割成独立的多个\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"若干独立的数据集和测试集可以用于训练机器学习模型\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 手动分割数据集\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 用多个独立的数据集训练模型\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"这里\"),t(\"code\",[s._v(\"X_test\")]),s._v(\"为两个独立的数据集（矩阵）\")])]),s._v(\" \"),t(\"p\",[s._v(\"建立模型并进行训练、测试\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"用\"),t(\"code\",[s._v(\"classifier.fit(x, y)\")]),s._v(\"进行训练，传入的是数据集\")]),s._v(\" \"),t(\"li\",[s._v(\"用\"),t(\"code\",[s._v(\"classifier.score(x, y)\")]),s._v(\"进行测试，传入的是准确的测试用例，即测试集\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 一旦拥有独立的训练和测试集，就可以使用fit方法学习机器学习模型\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 用score方法测试此方法\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 选择线性回归模型\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 建立线性回归模型\")]),s._v(\"\\nclf1 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                         multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'ovr'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 通过已有数据集进行学习\")]),s._v(\"\\nclf1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy1 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"Accuracy score of the LogisticRegression is \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.97\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"这里使用的是线性回归模型，\"),t(\"code\",[s._v(\"scikit_learn\")]),s._v(\"的\"),t(\"code\",[s._v(\"api\")]),s._v(\"在各模型中保持一致\")])]),s._v(\" \"),t(\"p\",[s._v(\"随机森林模型\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 同样我们还可以使用RandomForest模型进行学习，api基本保持一致\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"ensemble \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" RandomForestClassifier\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 建立模型\")]),s._v(\"\\nclf2 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" RandomForestClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n_estimators\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"100\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                              random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy2 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"Accuracy score of the RandomForestClassifier is \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.99\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"load-breast-cancer\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#load-breast-cancer\"}},[s._v(\"#\")]),s._v(\" \"),t(\"code\",[s._v(\"load_breast_cancer\")])]),s._v(\" \"),t(\"p\",[s._v(\"用同样的方法训练和测试\"),t(\"code\",[s._v(\"load_breast_cancer\")]),s._v(\"乳腺癌数据集\")]),s._v(\" \"),t(\"p\",[s._v(\"导入数据集并对数据集进行独立分割\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_breast_cancer\\n\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_breast_cancer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"len\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\")])]),t(\"p\",[s._v(\"使用\"),t(\"code\",[s._v(\"GradientBoostingClassifier\")]),s._v(\"梯度提升分类器建模进行训练和测试\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"ensemble \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" GradientBoostingClassifier\\nclf1 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" GradientBoostingClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n_estimators\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"100\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy11 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\")])]),t(\"p\",[s._v(\"这里提供另一种测试精度的方法，使用\"),t(\"code\",[s._v(\"predict\")]),s._v(\"预测函数对\"),t(\"code\",[s._v(\"X_test\")]),s._v(\"进行预测得到\"),t(\"code\",[s._v(\"y_pred\")]),s._v(\"，再调用\"),t(\"code\",[s._v(\"balanced_accuracy_score\")]),s._v(\"评估方法对\"),t(\"code\",[s._v(\"y_pred\")]),s._v(\"和\"),t(\"code\",[s._v(\"y_test\")]),s._v(\"进行比对，进行精准度测试\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"metrics \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" balanced_accuracy_score\\ny_pred \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf1\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"predict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy12 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" balanced_accuracy_score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_pred\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"accuracy11\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"accuracy12\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"这里\"),t(\"code\",[s._v(\"score\")]),s._v(\"函数和\"),t(\"code\",[s._v(\"balanced_accuracy_score\")]),s._v(\"方法的精准度测试结果并不一样\")])]),s._v(\" \"),t(\"p\",[s._v(\"使用其他的模型进行建模训练并测试\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"线性回归模型\")]),s._v(\" \"),t(\"li\",[s._v(\"随机森林模型\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\nclf2 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                          multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'ovr'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy2 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"accuracy2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"ensemble \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" RandomForestClassifier\\nclf3 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" RandomForestClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n_estimators\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"100\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf3\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy3 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf3\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"accuracy3\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\")])]),t(\"p\",[s._v(\"经测试，拟合效果梯度提升>随机森林>线性回归\")]),s._v(\" \"),t(\"h2\",{attrs:{id:\"preprocess-the-data\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#preprocess-the-data\"}},[s._v(\"#\")]),s._v(\" Preprocess the Data\")]),s._v(\" \"),t(\"blockquote\",[t(\"p\",[s._v(\"在训练和测试分类器之前预处理数据\")])]),s._v(\" \"),t(\"h3\",{attrs:{id:\"预处理数据集\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#预处理数据集\"}},[s._v(\"#\")]),s._v(\" 预处理数据集\")]),s._v(\" \"),t(\"p\",[s._v(\"正常的分割、训练、测试过程\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_digits\\n\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_digits\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\\nclf \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'auto'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"42\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'{} required {} iterations to be fitted'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"n_iter_\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"Accuracy score of the LogisticRegression is 0.96\")]),s._v(\" \"),t(\"li\",[s._v(\"LogisticRegression required 1000 iterations to be fitted\")])]),s._v(\" \"),t(\"p\",[s._v(\"用\"),t(\"code\",[s._v(\"MinMaxScaler\")]),s._v(\"对数据集进行预处理\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\\nscaler \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_train_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\nclf \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'auto'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"42\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'\\\\nAccuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'{} required {} iterations to be fitted'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"n_iter_\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"Accuracy score of the LogisticRegression is 0.97\")]),s._v(\" \"),t(\"li\",[s._v(\"LogisticRegression required 189 iterations to be fitted\")])]),s._v(\" \"),t(\"p\",[s._v(\"预处理的数据大大减少了训练时的迭代次数，能够有效提高训练效率\")]),s._v(\" \"),t(\"h3\",{attrs:{id:\"错误的预处理模式\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#错误的预处理模式\"}},[s._v(\"#\")]),s._v(\" 错误的预处理模式\")]),s._v(\" \"),t(\"p\",[s._v(\"预处理未拆分的数据集\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"即对\"),t(\"code\",[s._v(\"X\")]),s._v(\"直接进行预处理，再用\"),t(\"code\",[s._v(\"train_test_split\")]),s._v(\"方法拆分\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\\nscaler \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\nX_train_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\")])]),t(\"p\",[s._v(\"对训练集和测试集独立预处理\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"即多次使用\"),t(\"code\",[s._v(\"fit_transform\")]),s._v(\"对数据多次拟合，这将导致在不同的拟合结果下进行标准化\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\nscaler \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_train_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"scikit-learn-管道连接器\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#scikit-learn-管道连接器\"}},[s._v(\"#\")]),s._v(\" Scikit-Learn 管道连接器\")]),s._v(\" \"),t(\"p\",[s._v(\"使用管道连接器在训练的同时预处理数据\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"这里涉及到\"),t(\"code\",[s._v(\"preprocessing, pipeline, linear_model\")]),s._v(\"三个模块，前者提供数据标准化方法，中者构造管道，后者选定模型\")]),s._v(\" \"),t(\"li\",[s._v(\"使用\"),t(\"code\",[s._v(\"pipe = 9make_pipeline(预处理数据方法, 学习模型(模型设置))\")]),s._v(\"的形式构造管道\")]),s._v(\" \"),t(\"li\",[s._v(\"使用\"),t(\"code\",[s._v(\"pipe.fit/score\")]),s._v(\"函数对数据集进行训练和测试\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_digits\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_digits\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                     LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'auto'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\npipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"使用管道处理-breast-cancer\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#使用管道处理-breast-cancer\"}},[s._v(\"#\")]),s._v(\" 使用管道处理 \"),t(\"code\",[s._v(\"breast_cancer\")])]),s._v(\" \"),t(\"p\",[s._v(\"为什么要用管道训练，因为管道可以在\"),t(\"code\",[s._v(\"fit\")]),s._v(\"的同时进行多个操作，如预处理和分类器学习\")]),s._v(\" \"),t(\"ol\",[t(\"li\",[s._v(\"导入数据集：\"),t(\"code\",[s._v(\"sklearn.datasets\")])]),s._v(\" \"),t(\"li\",[s._v(\"拆分数据集：\"),t(\"code\",[s._v(\"sklearn.model_selection\")])]),s._v(\" \"),t(\"li\",[s._v(\"构建管道\\n\"),t(\"ul\",[t(\"li\",[s._v(\"数据预处理：\"),t(\"code\",[s._v(\"sklearn.preprocessing\")])]),s._v(\" \"),t(\"li\",[s._v(\"模型选择：\"),t(\"code\",[s._v(\"sklearn.linear_model\")])]),s._v(\" \"),t(\"li\",[s._v(\"管道构建：\"),t(\"code\",[s._v(\"from sklearn.pipeline import make_pipeline\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"模型测试：\"),t(\"code\",[s._v(\"score(test)\")]),s._v(\"或\"),t(\"code\",[s._v(\"from sklearn.metrics import balanced_accuracy_score(test, pred)\")])])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_breast_cancer\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_breast_cancer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SGDClassifier\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" SGDClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\npipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ny_pred \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"predict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"metrics \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" balanced_accuracy_score\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" balanced_accuracy_score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_pred\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"cross-validation\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#cross-validation\"}},[s._v(\"#\")]),s._v(\" Cross-Validation\")]),s._v(\" \"),t(\"blockquote\",[t(\"p\",[s._v(\"交叉验证，当数据越多越好时使用交叉验证的方式拆分数据集\")])]),s._v(\" \"),t(\"p\",[s._v(\"交叉验证的步骤如下\")]),s._v(\" \"),t(\"ol\",[t(\"li\",[s._v(\"导入数据：注意这里不需要独立分割数据，即使用\"),t(\"code\",[s._v(\"X,y\")]),s._v(\"即可\")]),s._v(\" \"),t(\"li\",[s._v(\"构建管道\\n\"),t(\"ul\",[t(\"li\",[s._v(\"选定模型\")]),s._v(\" \"),t(\"li\",[s._v(\"选定预处理方法\")]),s._v(\" \"),t(\"li\",[t(\"code\",[s._v(\"make_pipeline\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"交叉验证进行训练和测试\")]),s._v(\" \"),t(\"li\",[s._v(\"通过\"),t(\"code\",[s._v(\"DataFrame\")]),s._v(\"和\"),t(\"code\",[s._v(\"pyplot\")]),s._v(\"绘图\")])]),s._v(\" \"),t(\"h3\",{attrs:{id:\"导入数据并构建管道\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#导入数据并构建管道\"}},[s._v(\"#\")]),s._v(\" 导入数据并构建管道\")]),s._v(\" \"),t(\"p\",[s._v(\"导入数字识别数据集\"),t(\"code\",[s._v(\"load_digits\")]),s._v(\"，预处理模式选择\"),t(\"code\",[s._v(\"MinMaxScaler\")]),s._v(\"，学习模型选择\"),t(\"code\",[s._v(\"LogisticRegression\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_digits\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 导入数据\")]),s._v(\"\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_digits\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 构建管道\")]),s._v(\"\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                    LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'auto'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"交叉验证和绘图\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#交叉验证和绘图\"}},[s._v(\"#\")]),s._v(\" 交叉验证和绘图\")]),s._v(\" \"),t(\"p\",[s._v(\"从模块\"),t(\"code\",[s._v(\"model_selection\")]),s._v(\"中导入交叉验证函数\"),t(\"code\",[s._v(\"cross_validate\")]),s._v(\"（\"),t(\"code\",[s._v(\"train_test_split\")]),s._v(\"也在该模块），直接传入原数据集\"),t(\"code\",[s._v(\"X,y\")]),s._v(\"获取验证结果\"),t(\"code\",[s._v(\"scores\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 交叉验证\")]),s._v(\"\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\")])]),t(\"p\",[s._v(\"转化为\"),t(\"code\",[s._v(\"DataFrame\")]),s._v(\"输出并作图\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"使用\"),t(\"code\",[s._v(\"DataFrame\")]),s._v(\"自带的\"),t(\"code\",[s._v(\"boxplot\")]),s._v(\"函数做箱型图\")]),s._v(\" \"),t(\"li\",[s._v(\"要用\"),t(\"code\",[s._v(\"plt.show()\")]),s._v(\"进行展示\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 构建DataFrame并绘制箱型图\")]),s._v(\"\\ndf_scores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"df_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"   fit_time  score_time  test_score  train_score\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.120385\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000562\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.926544\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.988314\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.097318\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000464\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.943239\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.984975\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"2\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.098848\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000470\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.924875\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.993322\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(287)}}),s._v(\" \"),t(\"h3\",{attrs:{id:\"load-breast-cancer-2\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#load-breast-cancer-2\"}},[s._v(\"#\")]),s._v(\" \"),t(\"code\",[s._v(\"load_breast_cancer\")])]),s._v(\" \"),t(\"p\",[s._v(\"使用交叉验证在乳腺癌数据集上测试管道\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_breast_cancer\\n\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_breast_cancer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SGDClassifier\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" SGDClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"  scoring\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'balanced_accuracy'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                        cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\ndf_scores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"df_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"   fit_time  score_time  test_score  train_score\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.002559\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.017959\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.964907\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.985160\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.001544\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000525\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.959226\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.976757\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"2\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.001338\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000481\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.976050\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.987336\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"步骤与上完全相同\")]),s._v(\" \"),t(\"li\",[s._v(\"不同之处在于\\n\"),t(\"ul\",[t(\"li\",[s._v(\"数据集不同\")]),s._v(\" \"),t(\"li\",[s._v(\"学习模型使用\"),t(\"code\",[s._v(\"SGDClassifier\")])]),s._v(\" \"),t(\"li\",[s._v(\"预处理模式使用\"),t(\"code\",[s._v(\"StandardScaler\")])])])])]),s._v(\" \"),t(\"img\",{attrs:{src:a(288)}})])}),[],!1,null,null,null);t.default=e.exports}}]);","extractedComments":[]}