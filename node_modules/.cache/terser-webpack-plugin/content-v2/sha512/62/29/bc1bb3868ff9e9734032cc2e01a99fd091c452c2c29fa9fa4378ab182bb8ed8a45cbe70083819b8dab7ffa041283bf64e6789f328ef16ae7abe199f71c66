{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{473:function(s,t,a){s.exports=a.p+\"assets/img/Figure_16.f039ed24.png\"},474:function(s,t,a){s.exports=a.p+\"assets/img/Figure_17.be84cd0e.png\"},475:function(s,t,a){s.exports=a.p+\"assets/img/Figure_18.f039ed24.png\"},476:function(s,t,a){s.exports=a.p+\"assets/img/Figure_19.1a047c7d.png\"},477:function(s,t,a){s.exports=a.p+\"assets/img/Figure_20.8d026384.png\"},831:function(s,t,a){\"use strict\";a.r(t);var n=a(0),r=Object(n.a)({},(function(){var s=this,t=s._self._c;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":s.$parent.slotKey}},[t(\"blockquote\",[t(\"p\",[s._v(\"优化训练模式，并且处理非数字数据\")])]),s._v(\" \"),t(\"h2\",{attrs:{id:\"optimization\"}},[s._v(\"Optimization\")]),s._v(\" \"),t(\"blockquote\",[t(\"p\",[s._v(\"微调管道内部，超参数优化\")]),s._v(\" \"),t(\"p\",[s._v(\"Hyper-parameters optimization\")])]),s._v(\" \"),t(\"h3\",{attrs:{id:\"构建管道和准备数据\"}},[s._v(\"构建管道和准备数据\")]),s._v(\" \"),t(\"p\",[s._v(\"构建管道\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SGDClassifier\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" SGDClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\")])]),t(\"p\",[s._v(\"查看管道参数\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"get_params\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"p\",[s._v(\"准备数据\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_digits\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_digits\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"gridsearchcv-调优\"}},[s._v(\"GridSearchCV 调优\")]),s._v(\" \"),t(\"p\",[s._v(\"使用\"),t(\"code\",[s._v(\"GridSearchCV\")]),s._v(\"搜索当前训练集下的最优参数\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 使用网格搜索找到当前训练集下最优参数\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" GridSearchCV\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\\nparam \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__C'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__penalty'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l2'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l1'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\ngrid \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" GridSearchCV\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" param_grid\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"param\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ngrid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"get_params\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"这里要调优的参数为\"),t(\"code\",[s._v(\"C\")]),s._v(\"和\"),t(\"code\",[s._v(\"penalty\")]),s._v(\"，需要在\"),t(\"code\",[s._v(\"param\")]),s._v(\"手动中写明\")]),s._v(\" \"),t(\"li\",[s._v(\"注意这里的\"),t(\"code\",[s._v(\"grid\")]),s._v(\"就是一个机器学习模型，和管道\"),t(\"code\",[s._v(\"pipe\")]),s._v(\"，分类器\"),t(\"code\",[s._v(\"clf\")]),s._v(\"相同\")]),s._v(\" \"),t(\"li\",[s._v(\"只有当\"),t(\"code\",[s._v(\"grid\")]),s._v(\"已经经过训练，并且调用了\"),t(\"code\",[s._v(\"score\")]),s._v(\"函数后，其最优函数才会确定下来，否则不认为当前训练集已经结束\")])]),s._v(\" \"),t(\"p\",[s._v(\"查看各参数对训练的影响以及结果\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[s._v(\"df_grid \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"cv_results_\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"df_grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_logisticregression__C  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\". split0_train_score split1_train_score  split2_train_score  mean_train_score  std_train_score\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"       \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.126961\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.001999\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.006072\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.007825\")]),s._v(\"                         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.949889\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.953229\")]),s._v(\"            \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.949889\")]),s._v(\"          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.951002\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.001575\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\"       \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.247481\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.017783\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000620\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000040\")]),s._v(\"                         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.891982\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.909800\")]),s._v(\"            \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.904232\")]),s._v(\"          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.902004\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.007442\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"2\")]),s._v(\"       \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.425019\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.011945\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000617\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000032\")]),s._v(\"                         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.989978\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.988864\")]),s._v(\"            \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.984410\")]),s._v(\"          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.987751\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.002406\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),s._v(\"       \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.135990\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.046367\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000678\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000057\")]),s._v(\"                         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.982183\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.982183\")]),s._v(\"            \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.979955\")]),s._v(\"          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.981440\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.001050\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"4\")]),s._v(\"       \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.080702\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.094789\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000640\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000035\")]),s._v(\"                          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.998886\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.998886\")]),s._v(\"            \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.998886\")]),s._v(\"          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.998886\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000000\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5\")]),s._v(\"       \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5.193207\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.190867\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000609\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000019\")]),s._v(\"                          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.000000\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.000000\")]),s._v(\"            \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.000000\")]),s._v(\"          \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.000000\")]),s._v(\"         \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000000\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"6\")]),s._v(\" rows x \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"18\")]),s._v(\" columns\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\")])]),t(\"p\",[s._v(\"查看当前训练集下最优的\"),t(\"code\",[s._v(\"C/penalty\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"best_params_\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__C'\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin class-name\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),s._v(\", \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__penalty'\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin class-name\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l2'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"p\",[s._v(\"对模型\"),t(\"code\",[s._v(\"grid\")]),s._v(\"进行精准度测试\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[s._v(\"accuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"Accuracy score of the GridSearchCV is \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.97\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"交叉验证调优后管道\"}},[s._v(\"交叉验证调优后管道\")]),s._v(\" \"),t(\"p\",[s._v(\"前面已经提到，这里的\"),t(\"code\",[s._v(\"grid\")]),s._v(\"是同\"),t(\"code\",[s._v(\"clf/pipe\")]),s._v(\"一样的机器学习模型，自然可以对原数据进行交叉验证\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"df_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"    fit_time  score_time  test_score  train_score\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"23.017125\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000651\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.928214\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.985810\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"25.200372\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000676\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.946578\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.997496\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"2\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"23.103306\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000675\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.924875\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.993322\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(473)}}),s._v(\" \"),t(\"h3\",{attrs:{id:\"调优训练-breast-cancer\"}},[s._v(\"调优训练 breast_cancer\")]),s._v(\" \"),t(\"p\",[s._v(\"在乳腺癌数据集上对管道进行调优并训练测试\")]),s._v(\" \"),t(\"ol\",[t(\"li\",[s._v(\"导入数据，分割数据\")]),s._v(\" \"),t(\"li\",[s._v(\"构建管道，调优参数\")]),s._v(\" \"),t(\"li\",[s._v(\"训练测试，交叉验证\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_breast_cancer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"metrics \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" balanced_accuracy_score\\n\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_breast_cancer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" stratify\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SGDClassifier\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" SGDClassifier\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" GridSearchCV\\n\\nparam \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sgdclassifier__loss'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'hinge'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'log'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sgdclassifier__penalty'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l2'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l1'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\ngrid \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" GridSearchCV\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" param_grid\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"param\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ngrid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" scoring\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'balanced_accuracy'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                        cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"best_params_\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"df_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"the accuracy is \"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sgdclassifier__loss'\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin class-name\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'hinge'\")]),s._v(\", \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sgdclassifier__penalty'\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin class-name\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l1'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n   fit_time  score_time  test_score  train_score\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.031983\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000585\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.962067\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.980303\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.034171\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000492\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.949343\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.987261\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"2\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.032296\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.000593\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.963445\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.988076\")]),s._v(\"\\n\\nthe accuracy is \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.9440559440559441\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(474)}}),s._v(\" \"),t(\"h3\",{attrs:{id:\"管道使用总结\"}},[s._v(\"管道使用总结\")]),s._v(\" \"),t(\"p\",[s._v(\"使用\"),t(\"code\",[s._v(\"scikit-learn\")]),s._v(\"十行以内训练并测试一个管道，包括数据预处理、参数调优、交叉验证\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" MinMaxScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" GridSearchCV\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"datasets \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" load_digits\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\nX\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" load_digits\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"return_X_y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"MinMaxScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                     LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'saga'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" multi_class\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'auto'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"42\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nparam \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__C'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__penalty'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l2'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'l1'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\ngrid \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" GridSearchCV\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" param_grid\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"param\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nscores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(475)}}),s._v(\" \"),t(\"h2\",{attrs:{id:\"heterogeneous-data\"}},[s._v(\"Heterogeneous Data\")]),s._v(\" \"),t(\"blockquote\",[t(\"p\",[s._v(\"Heterogeneous data\")]),s._v(\" \"),t(\"p\",[s._v(\"处理除数字以外的数据\")])]),s._v(\" \"),t(\"p\",[s._v(\"导入外部数据集\")]),s._v(\" \"),t(\"p\",[s._v(\"注意\"),t(\"code\",[s._v(\"shell\")]),s._v(\"的位置，这里找的是当前\"),t(\"code\",[s._v(\"shell\")]),s._v(\"路径的相对路径\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"通过\"),t(\"code\",[s._v(\"os.getcwd()\")]),s._v(\"获取当前路径（pwd）\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" os\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"os\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"getcwd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\ndata \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"read_csv\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"os\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"path\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"join\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'data'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'titanic_openml.csv'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" na_values\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'?'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"head\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"7\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"tail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"4\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"先拟合再学习\"}},[s._v(\"先拟合再学习\")]),s._v(\" \"),t(\"p\",[s._v(\"从原始数据中提取出数据集\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"在该泰坦尼克模型中，自变量为年龄、性别、是否上船、恐惧等因素，因变量为是否存活\")])]),s._v(\" \"),t(\"p\",[s._v(\"分割数据集为训练集和测试集，采用线性回归模型进行学习\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[s._v(\"y \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'survived'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"drop\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"columns\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'survived'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\\nclf \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[s._v(\"必然报错，因为\"),t(\"code\",[s._v(\"fit\")]),s._v(\"方法接收的数据集要求数据为数字型，而这里的很多数据如性别、是否上船并不是数字数据\")])]),s._v(\" \"),t(\"p\",[s._v(\"使用管道处理非数字数据，同时使用管道标准化数字数据，这里实际上都是预处理数据的过程\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"处理非数字数据，即转化为数字数据同时处理缺失数据\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"SimpleImputer(strategy='constant')\")])]),s._v(\" \"),t(\"li\",[t(\"code\",[s._v(\"OneHotEncoder()\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"标准化数字数据同时处理缺失数据\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"SimpleImputer(strategy='mean')\")])]),s._v(\" \"),t(\"li\",[t(\"code\",[s._v(\"StandardScaler()\")])])])])]),s._v(\" \"),t(\"p\",[t(\"code\",[s._v(\"OneHotEncoder\")]),s._v(\"示例\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"impute \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SimpleImputer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" OneHotEncoder\\nohe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'constant'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" OneHotEncoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_encoded \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" ohe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sex'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'embarked'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_encoded\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"toarray\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\".\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\".\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\".\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"..\")]),s._v(\".\\n \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\".\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\".\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\". \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\".\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\")])]),t(\"p\",[s._v(\"处理\"),t(\"code\",[s._v(\"titanic\")]),s._v(\"数据\")]),s._v(\" \"),t(\"p\",[s._v(\"1、提取非数字列和数字列\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[s._v(\"col_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sex'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'embarked'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\ncol_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'age'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sibsp'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'parch'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'fare'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\\nX_train_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX_test_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX_train_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX_test_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\")])]),t(\"p\",[s._v(\"2、构建管道预处理数据\")]),s._v(\" \"),t(\"p\",[s._v(\"为什么要用管道而不是单独预处理，因为需要同时处理缺失数据\")]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"数字化非数字数据\")]),s._v(\" \"),t(\"li\",[s._v(\"标准化数字数据\")]),s._v(\" \"),t(\"li\",[s._v(\"处理缺失数据\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"impute \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SimpleImputer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" OneHotEncoder\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\\nscaler_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'constant'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" OneHotEncoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nscaler_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'mean'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\nX_train_cat_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_cat_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_train_num_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" scaler_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_tes\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\")])]),t(\"p\",[s._v(\"3、合并预处理后的数字数据和非数字数据，采用矩阵横向合并的方法（即合并列为一张大表）\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" numpy \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" np\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" scipy \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" sparse\\nX_train_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hstack\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_cat_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \\n                sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"csr_matrix\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_num_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hstack\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_cat_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \\n                sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"csr_matrix\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_num_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\")])]),t(\"p\",[s._v(\"4、现在已经有完整的数字标准化后的训练、测试数据，直接构建模型开始学习\"),t(\"code\",[s._v(\"(fit)\")]),s._v(\"即可\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\\nclf \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"Accuracy score of the {} is {:.2f}\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"通过管道学习\"}},[s._v(\"通过管道学习\")]),s._v(\" \"),t(\"p\",[s._v(\"上述过程可以概括为：\")]),s._v(\" \"),t(\"ol\",[t(\"li\",[s._v(\"预处理数据\\n\"),t(\"ul\",[t(\"li\",[s._v(\"提取数据的非数字列和数字列\")]),s._v(\" \"),t(\"li\",[s._v(\"通过管道分别数字化、标准化处理非数字、数字数据，同时处理缺失数据\")]),s._v(\" \"),t(\"li\",[s._v(\"合并处理后的数据\")])])]),s._v(\" \"),t(\"li\",[s._v(\"建立模型学习并测试\")])]),s._v(\" \"),t(\"p\",[s._v(\"和之前的学习一样，上述过程可以揉合到一个管道中进行，即构建一个含有预处理功能和学习功能的管道\")]),s._v(\" \"),t(\"p\",[s._v(\"这里有一个问题，就是对于数字数据和非数字数据，其预处理的方式并不同，所以管道的预处理功能应该针对特定列有不同的处理方法\")]),s._v(\" \"),t(\"p\",[s._v(\"这里用到\"),t(\"code\",[s._v(\"sklearn.compose.make_column_transformer(transformer, col_name)\")]),s._v(\"合并多个管道并使之作用于不同列\")]),s._v(\" \"),t(\"ol\",[t(\"li\",[s._v(\"导入数据，独立分割\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"data = pd.read_csv(os.path.join(), na_values='?')\")])]),s._v(\" \"),t(\"li\",[t(\"code\",[s._v(\"train_test_split\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"构建预处理管道\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"make_pipeline(空值处理器, 预处理器)\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"合并预处理管道\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"make_column_transformer((预处理管道, 列名)...)\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"构建总管道\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"make_pipeline(预处理器, 分类器)\")])])])]),s._v(\" \"),t(\"li\",[s._v(\"学习并测试\\n\"),t(\"ul\",[t(\"li\",[t(\"code\",[s._v(\"fit()/score()\")])])])])]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" preprocessing\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" os\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" OneHotEncoder\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"impute \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SimpleImputer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" numpy \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" np\\n\\ndata \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"read_csv\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"os\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"path\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"join\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'data'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'titanic_openml.csv'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" na_values\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'?'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ny \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'survived'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"drop\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"columns\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'survived'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(X)\")]),s._v(\"\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(y_train)\")]),s._v(\"\\n\\ncol_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sex'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'embarked'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\ncol_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'age'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sibsp'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'parch'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'fare'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\\npre_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'constant'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" OneHotEncoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"handle_unknown\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'ignore'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\npre_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'mean'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"compose \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_column_transformer\\n\\npreprocessor \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_column_transformer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pre_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" col_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pre_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" col_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"preprocessor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\npipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'Accuracy score of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"优化管道参数\"}},[s._v(\"优化管道参数\")]),s._v(\" \"),t(\"p\",[s._v(\"在上述包含预处理功能和学习功能的管道的基础上，在正式测试之前使用网格搜索\"),t(\"code\",[s._v(\"GridSearchCV\")]),s._v(\"对其参数进行调优\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" GridSearchCV\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 调优参数\")]),s._v(\"\\nparam \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'columntransformer__pipeline-2__simpleimputer__strategy'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'mean'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'median'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__C'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\ngrid \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" GridSearchCV\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" param_grid\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"param\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\ngrid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 交叉验证得分\")]),s._v(\"\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" scoring\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'balanced_accuracy'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 绘制箱型图\")]),s._v(\"\\ndf_scores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ndf_scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(476)}}),s._v(\" \"),t(\"h3\",{attrs:{id:\"adult-openml-csv\"}},[s._v(\"adult_openml.csv\")]),s._v(\" \"),t(\"p\",[s._v(\"使用同样的方法处理\"),t(\"code\",[s._v(\"adult_openml\")]),s._v(\"数据集\")]),s._v(\" \"),t(\"h4\",{attrs:{id:\"预处理再拟合\"}},[s._v(\"预处理再拟合\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" os\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\\n\\ndata \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"read_csv\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"os\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"path\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"join\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'data'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'adult_openml.csv'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" na_values\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'?'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(data.head(7))\")]),s._v(\"\\n\\ny \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'class'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"drop\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"columns\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'class'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'fnlwgt'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'capitalgain'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'capitalloss'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(y_train)\")]),s._v(\"\\n\\ncol_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'workclass'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'education'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'marital-status'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'relationship'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'race'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sex'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'native-country'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\ncol_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'age'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'education-num'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'hoursperweek'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\\nX_train_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX_test_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX_train_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX_test_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"col_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" KBinsDiscretizer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" OneHotEncoder\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"impute \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SimpleImputer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\\n\\ncat_pipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'constant'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" OneHotEncoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nnum_pipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'mean'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\nX_train_cat_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cat_pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_cat_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" cat_pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_train_num_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" num_pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_num_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" num_pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" numpy \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" np\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" scipy \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" sparse\\n\\nX_train_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hstack\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_cat_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \\n                sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"csr_matrix\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_num_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nX_test_scaled \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hstack\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_cat_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \\n                sparse\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"csr_matrix\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_num_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\\nclf \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nclf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test_scaled\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'accuracy of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"clf\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"51\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"52\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"accuracy of the LogisticRegression is \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.83\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"h4\",{attrs:{id:\"优化管道处理\"}},[s._v(\"优化管道处理\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" os\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" pandas \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" pd\\n\\ndata \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"read_csv\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"os\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"path\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"join\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'data'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'adult_openml.csv'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" na_values\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'?'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(data.head(3))\")]),s._v(\"\\ny \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'class'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\nX \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" data\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"drop\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"columns\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'class'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'fnlwgt'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'capitalgain'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'capitalloss'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(X)\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LabelEncoder\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" train_test_split\\n\\nX_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" train_test_split\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" random_state\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# print(y_train)\")]),s._v(\"\\nencoder \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" LabelEncoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ny_train \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" encoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit_transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ny_test \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" encoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"transform\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pipeline \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_pipeline\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"impute \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" SimpleImputer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" StandardScaler\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"preprocessing \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" OneHotEncoder\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"compose \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" make_column_transformer\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"linear_model \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" LogisticRegression\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" GridSearchCV\\n\\npre_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'constant'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" OneHotEncoder\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"handle_unknown\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'ignore'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\npre_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"SimpleImputer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"strategy\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'mean'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" StandardScaler\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\ncol_cat \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'workclass'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'education'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'marital-status'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'relationship'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'race'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'sex'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'native-country'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\ncol_num \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'age'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'education-num'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'hoursperweek'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\\npreprocessor \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_column_transformer\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pre_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" col_cat\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pre_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" col_num\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# preprocessor.fit(X_train, y_train)\")]),s._v(\"\\n\\npipe \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" make_pipeline\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"preprocessor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" LogisticRegression\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"solver\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'lbfgs'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" max_iter\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5000\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# pipe.fit(X_train, y_train)\")]),s._v(\"\\n\\nparam \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'logisticregression__C'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\ngrid \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" GridSearchCV\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"pipe\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" param_grid\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\"param\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"5\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\ngrid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"fit\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_train\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\naccuracy \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"score\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"X_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y_test\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'accuracy of the {} is {:.2f}'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token builtin\"}},[s._v(\"format\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__class__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"__name__\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" accuracy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"from\")]),s._v(\" sklearn\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"model_selection \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" cross_validate\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" matplotlib\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"pyplot \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"as\")]),s._v(\" plt\\nscores \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" pd\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"DataFrame\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"cross_validate\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"grid\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" X\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" y\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" scoring\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'balanced_accuracy'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" cv\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"3\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" n_jobs\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" return_train_score\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"True\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nscores\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'train_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v(\"'test_score'\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"boxplot\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"whis\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"10\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\nplt\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"show\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\")])]),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"accuracy of the GridSearchCV is \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.83\")]),s._v(\"\\n\\n    fit_time  score_time  test_score  train_score\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"11.303147\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.064652\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.719383\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.729532\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12.427096\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.067366\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.730889\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.723769\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"2\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12.042301\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.078128\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.723290\")]),s._v(\"     \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.725647\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\")])]),t(\"img\",{attrs:{src:a(477)}})])}),[],!1,null,null,null);t.default=r.exports}}]);","extractedComments":[]}